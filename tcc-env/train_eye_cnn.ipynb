{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0525658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d9a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets de prÃ©-processamento carregados\n",
    "x_train = np.load('dataset/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('dataset/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('dataset/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('dataset/y_val.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a1463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow(\n",
    "    x=x_val, y=y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c406810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 10:40:57.923264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-09 10:40:57.923298: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-09 10:40:57.923325: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (guilherme-Aspire-E5-574): /proc/driver/nvidia/version does not exist\n",
      "2022-01-09 10:40:57.923570: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(26, 34, 1))\n",
    "\n",
    "net = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "\n",
    "net = Dense(512)(net)\n",
    "net = Activation('relu')(net)\n",
    "net = Dense(1)(net)\n",
    "outputs = Activation('sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308065a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5278 - acc: 0.7151\n",
      "Epoch 00001: val_acc improved from -inf to 0.82966, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 4s 48ms/step - loss: 0.5278 - acc: 0.7151 - val_loss: 0.3864 - val_acc: 0.8297 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3185 - acc: 0.8672\n",
      "Epoch 00002: val_acc improved from 0.82966 to 0.88181, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.3185 - acc: 0.8672 - val_loss: 0.2683 - val_acc: 0.8818 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2371 - acc: 0.9035\n",
      "Epoch 00003: val_acc improved from 0.88181 to 0.94322, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.2371 - acc: 0.9035 - val_loss: 0.1530 - val_acc: 0.9432 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1732 - acc: 0.9304\n",
      "Epoch 00004: val_acc improved from 0.94322 to 0.97103, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1732 - acc: 0.9304 - val_loss: 0.1005 - val_acc: 0.9710 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9429\n",
      "Epoch 00005: val_acc improved from 0.97103 to 0.97914, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.1532 - acc: 0.9428 - val_loss: 0.0617 - val_acc: 0.9791 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1165 - acc: 0.9597\n",
      "Epoch 00006: val_acc improved from 0.97914 to 0.98262, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.1165 - acc: 0.9597 - val_loss: 0.0656 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1143 - acc: 0.9627\n",
      "Epoch 00007: val_acc did not improve from 0.98262\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.1143 - acc: 0.9627 - val_loss: 0.0815 - val_acc: 0.9791 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1045 - acc: 0.9657\n",
      "Epoch 00008: val_acc did not improve from 0.98262\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.1045 - acc: 0.9657 - val_loss: 0.1129 - val_acc: 0.9676 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1198 - acc: 0.9577\n",
      "Epoch 00009: val_acc did not improve from 0.98262\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.1198 - acc: 0.9577 - val_loss: 0.1196 - val_acc: 0.9641 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0980 - acc: 0.9642\n",
      "Epoch 00010: val_acc improved from 0.98262 to 0.98494, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0980 - acc: 0.9642 - val_loss: 0.0436 - val_acc: 0.9849 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0788 - acc: 0.9736\n",
      "Epoch 00011: val_acc improved from 0.98494 to 0.99073, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0788 - acc: 0.9736 - val_loss: 0.0409 - val_acc: 0.9907 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0863 - acc: 0.9722\n",
      "Epoch 00012: val_acc did not improve from 0.99073\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0863 - acc: 0.9722 - val_loss: 0.0342 - val_acc: 0.9884 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9803\n",
      "Epoch 00013: val_acc improved from 0.99073 to 0.99305, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0577 - acc: 0.9806 - val_loss: 0.0369 - val_acc: 0.9930 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9788\n",
      "Epoch 00014: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.0676 - acc: 0.9781 - val_loss: 0.0569 - val_acc: 0.9826 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9853\n",
      "Epoch 00015: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0515 - acc: 0.9856 - val_loss: 0.0290 - val_acc: 0.9907 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0467 - acc: 0.9826\n",
      "Epoch 00016: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0467 - acc: 0.9826 - val_loss: 0.0379 - val_acc: 0.9919 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9828\n",
      "Epoch 00017: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0497 - acc: 0.9831 - val_loss: 0.0272 - val_acc: 0.9919 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9879\n",
      "Epoch 00018: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.0312 - acc: 0.9876 - val_loss: 0.0710 - val_acc: 0.9849 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0514 - acc: 0.9801\n",
      "Epoch 00019: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0514 - acc: 0.9801 - val_loss: 0.0445 - val_acc: 0.9849 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9864\n",
      "Epoch 00020: val_acc did not improve from 0.99305\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0432 - acc: 0.9866 - val_loss: 0.0347 - val_acc: 0.9930 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0482 - acc: 0.9841\n",
      "Epoch 00021: val_acc improved from 0.99305 to 0.99537, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 0.0482 - acc: 0.9841 - val_loss: 0.0281 - val_acc: 0.9954 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.9901\n",
      "Epoch 00022: val_acc did not improve from 0.99537\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0382 - acc: 0.9901 - val_loss: 0.0328 - val_acc: 0.9930 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9899\n",
      "Epoch 00023: val_acc improved from 0.99537 to 0.99652, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0357 - acc: 0.9896 - val_loss: 0.0213 - val_acc: 0.9965 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0421 - acc: 0.9851\n",
      "Epoch 00024: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0421 - acc: 0.9851 - val_loss: 0.0526 - val_acc: 0.9873 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9894\n",
      "Epoch 00025: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0399 - acc: 0.9896 - val_loss: 0.0253 - val_acc: 0.9942 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9909\n",
      "Epoch 00026: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0198 - acc: 0.9910 - val_loss: 0.0285 - val_acc: 0.9954 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9944\n",
      "Epoch 00027: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.0187 - acc: 0.9945 - val_loss: 0.0270 - val_acc: 0.9930 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.9935\n",
      "Epoch 00028: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0339 - val_acc: 0.9954 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9944\n",
      "Epoch 00029: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0175 - acc: 0.9940 - val_loss: 0.0260 - val_acc: 0.9896 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9818\n",
      "Epoch 00030: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0439 - acc: 0.9821 - val_loss: 0.0182 - val_acc: 0.9942 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0221 - acc: 0.9935\n",
      "Epoch 00031: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0221 - acc: 0.9935 - val_loss: 0.0295 - val_acc: 0.9919 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0184 - acc: 0.9940\n",
      "Epoch 00032: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0357 - val_acc: 0.9873 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.9955\n",
      "Epoch 00033: val_acc did not improve from 0.99652\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0316 - val_acc: 0.9884 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0137 - acc: 0.9945\n",
      "Epoch 00034: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0137 - acc: 0.9945 - val_loss: 0.0283 - val_acc: 0.9930 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9970\n",
      "Epoch 00035: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.0212 - val_acc: 0.9954 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9990\n",
      "Epoch 00036: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0055 - acc: 0.9990 - val_loss: 0.0212 - val_acc: 0.9942 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.9975\n",
      "Epoch 00037: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0067 - acc: 0.9975 - val_loss: 0.0302 - val_acc: 0.9919 - lr: 2.0000e-04\n",
      "Epoch 38/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 00038: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0264 - val_acc: 0.9954 - lr: 2.0000e-04\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0077 - acc: 0.9975\n",
      "Epoch 00039: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0164 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9960\n",
      "Epoch 00040: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0098 - acc: 0.9960 - val_loss: 0.0190 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9990\n",
      "Epoch 00041: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0071 - acc: 0.9990 - val_loss: 0.0223 - val_acc: 0.9942 - lr: 2.0000e-04\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 00042: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0187 - val_acc: 0.9965 - lr: 2.0000e-04\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9980\n",
      "Epoch 00043: val_acc did not improve from 0.99652\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0226 - val_acc: 0.9942 - lr: 2.0000e-04\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 00044: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0237 - val_acc: 0.9930 - lr: 4.0000e-05\n",
      "Epoch 45/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9975\n",
      "Epoch 00045: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0220 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0056 - acc: 0.9990\n",
      "Epoch 00046: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0056 - acc: 0.9990 - val_loss: 0.0228 - val_acc: 0.9942 - lr: 4.0000e-05\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 00047: val_acc did not improve from 0.99652\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.0222 - val_acc: 0.9954 - lr: 4.0000e-05\n",
      "Epoch 48/50\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 00048: val_acc improved from 0.99652 to 0.99768, saving model to models/2022_01_09_11_02_24.h5\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.0073 - acc: 0.9980 - val_loss: 0.0198 - val_acc: 0.9977 - lr: 4.0000e-05\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0060 - acc: 0.9975\n",
      "Epoch 00049: val_acc did not improve from 0.99768\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.0207 - val_acc: 0.9965 - lr: 4.0000e-05\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 00050: val_acc did not improve from 0.99768\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.0103 - acc: 0.9965 - val_loss: 0.0184 - val_acc: 0.9977 - lr: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1314250040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "\n",
    "model.fit(\n",
    "    train_generator, epochs=50, validation_data=val_generator,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/%s.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c1ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9976825028968713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12695/2331932957.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_pred_logical = (y_pred > 0.5).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfeb3fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Documentos/.virtualenvs/tcc-env/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(y_pred, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162c803",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-env",
   "language": "python",
   "name": "tcc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
