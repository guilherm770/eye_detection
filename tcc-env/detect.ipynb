{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93336f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import time\n",
    "import ipynb.fs.full.crop_eye_func as cef\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff5371f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 34, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 17, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 17, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               786944    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 880,129\n",
      "Trainable params: 880,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# configurar reprodutor de aúdio\n",
    "mixer.init()\n",
    "mixer.music.load('alarme.wav')\n",
    "mixer.music.set_volume(1)\n",
    "\n",
    "# tamanho da janela de apresentação\n",
    "im_size = (34, 26)\n",
    "\n",
    "# contar tempo que os olhos permanecem fechados\n",
    "eye_timer = 0\n",
    "\n",
    "# variáveis auxiliares de cálculo de fps\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "# hog - detecção de face\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# landmark detection - detecção ocular\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# modelo de classificação ocular\n",
    "model = load_model('models/2022_01_09_11_02_24.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e843e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "# inicialização da câmera\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret,img = cap.read()\n",
    "i = 0\n",
    "\n",
    "while ret:\n",
    "    # frame\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.resize(img, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "    \n",
    "    # imagem em escala cinza para melhorar o processamento\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    # cálculo fps\n",
    "    new_frame_time = time.time()\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    fps = \"{:.2f}\".format(fps)\n",
    "    prev_frame_time = new_frame_time\n",
    "    fps = str(fps)\n",
    " \n",
    "    # apresentação do fps na tela\n",
    "    cv2.putText(img, \"FPS:\" + fps, (30,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = cef.crop_eye(img=img, gray=gray, eye_points=shapes[36:42], im_size=im_size)\n",
    "        eye_img_r, eye_rect_r = cef.crop_eye(img=img, gray=gray, eye_points=shapes[42:48], im_size=im_size)\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=im_size)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=im_size)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "        \n",
    "        # janelas de apresentação com olho esquerdo e direito\n",
    "        cv2.imshow('l', eye_img_l)\n",
    "        cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, im_size[1], im_size[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, im_size[1], im_size[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_l = model.predict(eye_input_l)\n",
    "        pred_r = model.predict(eye_input_r)\n",
    "        \n",
    "        # condições para vizualização\n",
    "        limiar = 0.01\n",
    "        state_l = 'aberto' if pred_l > limiar else 'fechado'\n",
    "        state_r = 'aberto' if pred_r > limiar else 'fechado'\n",
    "        \n",
    "        # alarme\n",
    "        if (state_l == 'fechado' and state_r == 'fechado' and eye_timer == 0):\n",
    "            eye_timer = time.time()\n",
    "            mixer.music.pause()\n",
    "        elif (state_l == 'fechado' and state_r == 'fechado' and eye_timer != 0):\n",
    "            if (time.time() - eye_timer >= 4):\n",
    "                cv2.putText(img, \"ALARME!!!\", (110,230), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "                mixer.music.play()\n",
    "        else:\n",
    "            eye_timer = 0\n",
    "            mixer.music.pause()\n",
    "        \n",
    "        # esboço do retângulo ao redor dos olhos\n",
    "        if state_l == 'aberto':\n",
    "            cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,128,0), thickness=1)\n",
    "        else:\n",
    "            cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,0,255), thickness=1)\n",
    "            \n",
    "        if state_r == 'aberto':\n",
    "            cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,128,0), thickness=1)\n",
    "        else:\n",
    "            cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,0,255), thickness=1)\n",
    "        \n",
    "        # texto indicando o estado dos olhos\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255,255,255), 1)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255,255,255), 1)\n",
    "        \n",
    "    # janela de apresentação com a face\n",
    "    cv2.imshow('img',img)\n",
    "    i += 1\n",
    "    # tecle 'q' para quebrar o loop\n",
    "    if(cv2.waitKey(1) == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f6fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35ebdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-env",
   "language": "python",
   "name": "tcc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
